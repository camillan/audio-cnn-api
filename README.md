# ğŸ· Audio Classification API with CNN + FastAPI

A lightweight, end-to-end audio classification system trained on the UrbanSound8K dataset. It uses MFCC spectrograms, a custom PyTorch CNN, and is deployed via a FastAPI web server with support for `.wav` file uploads.

## ğŸ” What It Does

* ğŸ¹ Accepts `.wav` audio files via a POST endpoint
* ğŸ“Š Converts audio into MFCC spectrograms
* ğŸ§  Predicts one of 10 common urban sound classes using a trained CNN
* â†º Returns the predicted label as a JSON response

## ğŸš€ How to Run It

### 1. Clone the repo and install dependencies

```bash
git clone https://github.com/camillan/audio-cnn-api.git
cd audio-cnn-api
pip install -r requirements.txt
```

### 2. Train the model

```bash
python train/train_cnn.py
```

This will:

* Download UrbanSound8K using `soundata`
* Extract MFCCs
* Train a CNN
* Save the model to `model/cnn_model.pth` and `label_mapping.npy`

### 3. Start the API server

```bash
uvicorn app.main:app --reload
```

Visit [http://localhost:8000/docs](http://localhost:8000/docs) to test it via Swagger UI.

---

## ğŸ§ª Test with a Sample `.wav`

Use any `.wav` from:

```bash
~/sound_datasets/urbansound8k/audio/fold1/
```

Or upload your own!

---

## ğŸ› ï¸ Tech Stack

* `FastAPI` â€“ API for real-time prediction
* `PyTorch` â€“ Lightweight CNN for MFCC classification
* `librosa` â€“ Audio preprocessing
* `soundata` â€“ UrbanSound8K dataset download & management
* `numpy`, `scikit-learn` â€“ Utilities

---

## ğŸ’¡ Ideas for Improvements

* Add confidence scores or top-3 predictions
* Add Streamlit/Gradio UI
* Containerize with Docker
* Deploy on Hugging Face Spaces or Render
* Support other datasets or languages

---

## ğŸ§  About the Author

This project was built as part of my transition into Machine Learning Engineering. It demonstrates real-world ML deployment skills, including data ingestion, model serving, and API design.

Feel free to fork or reach out!
